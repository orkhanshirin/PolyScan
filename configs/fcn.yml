# model architecture
model:
  name: "fcn"
  experiment_name: "fcn"  # auto-generated runs will be fcn_YYYYMMDD_HHMM
  params:
    in_channels: 3        # 1 for grayscale, 3 for RGB
    init_filters: 32      # initial convolution filters
    num_classes: 2        # background + polyp

# training parameters
training:
  epochs: 150             # longer training for convergence
  batch_size: 16          # FCN is memory-efficient
  optimizer:
    lr: 0.001             # higher learning rate than UNet
    weight_decay: 1e-4    # L2 regularization
  scheduler:
    name: "step"          # step learning rate decay
    step_size: 50         # decay every 50 epochs
    gamma: 0.1            # LR multiplier at each step

# data configuration
data:
  root_dir: "data"
  metadata_file: "metadata.csv"
  split_ratios: [0.7, 0.15, 0.15]  # train/val/test
  augmentations:                   # basic spatial transforms
    - name: HorizontalFlip
      probability: 0.5
    - name: VerticalFlip
      probability: 0.3
    - name: RandomRotate
      degrees: 25

# checkpointing
checkpoint:
  save_dir: "runs"       # will create runs/fcn_YYYYMMDD_HHMM
  save_interval: 10      # save every 10 epochs
  keep_top_k: 3          # only keep 3 best checkpoints